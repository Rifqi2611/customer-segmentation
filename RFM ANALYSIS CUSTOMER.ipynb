{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b9717f7-d5a0-490b-8dbe-bfb72abd087b",
   "metadata": {},
   "source": [
    "# RFM ANALYSIS CUSTOMER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4928e1-9d88-4381-96b2-8fc21782cdba",
   "metadata": {},
   "source": [
    "## IMPORT IMPORTANT MODUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1591b3-17c3-4b7c-a785-2bcd0b01c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac234b-9ff6-48cb-96cf-5e20c330144e",
   "metadata": {},
   "source": [
    "## LOAD & PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0da9026-d697-4e15-9819-422b37d8914e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load RFM data from a CSV file, clean and preprocess necessary columns.\n",
    "\n",
    "    Parameters:\n",
    "    filepath (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned and preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath, delimiter=',')\n",
    "    df.columns = [col.lower() for col in df.columns]\n",
    "    \n",
    "    df['buss_date'] = pd.to_datetime(df['buss_date'])\n",
    "    df['recency'] = pd.to_datetime(df['recency'])\n",
    "    df['id'] = pd.Series(range(1, len(df) + 1)).astype(str).str.zfill(7)\n",
    "    df['kc'] = df['kc'].astype(str).str.zfill(4)\n",
    "    df['loan_status'] = df['loan_status'].apply(lambda x: 1 if x == 'YES' else 0)\n",
    "    df.drop(columns=['cif'], inplace=True)\n",
    "    \n",
    "    df['recency'] = (df['buss_date'] - df['recency']).dt.days\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c850031a-8d72-4ff1-b18e-b41d30a9c52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalization ---\n",
    "def normalize_columns(df: pd.DataFrame, cols: list) -> (pd.DataFrame, dict):\n",
    "    \"\"\"\n",
    "    Normalize selected columns using min-max scaling.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing features.\n",
    "    cols (list): List of column names to normalize.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with normalized columns.\n",
    "    \"\"\"\n",
    "    original_values = {}\n",
    "    for col in cols:\n",
    "        min_val, max_val = df[col].min(), df[col].max()\n",
    "        original_values[col] = (min_val, max_val)\n",
    "        df[col] = (df[col] - min_val) / (max_val - min_val)\n",
    "    return df, original_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cef340-8f4f-45a5-9d23-a3ce37da3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Denormalize ---\n",
    "def denormalize_columns(df: pd.DataFrame, cols: list, original_values: dict) -> pd.DataFrame:\n",
    "    \"\"\"     \n",
    "    Denormalize selected columns using min-max scaling.\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing features.\n",
    "    cols (list): List of column names to denormalize.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with denormalized columns.\n",
    "    \"\"\" \n",
    "    for col in cols:\n",
    "        min_val, max_val = original_values[col]\n",
    "        df[col] = df[col] * (max_val - min_val) + min_val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "748fec0a-35e4-46a4-9ebf-109ac4ad9cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Elbow Method ---\n",
    "def find_optimal_k(data: pd.DataFrame, feature: str, max_k: int = 10) -> int:\n",
    "    \"\"\" \n",
    "    Determine the optimal number of clusters (k) for K-Means clustering using the Elbow Method.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The DataFrame containing the feature to be clustered.\n",
    "    feature (str): The column name (feature) on which K-Means will be applied.\n",
    "    max_k (int): The maximum number of clusters to test (default is 10).\n",
    "\n",
    "    Returns:\n",
    "    int: The optimal number of clusters based on the \"elbow\" point in the WCSS curve. \n",
    "         If the elbow is not detected, defaults to 3.\n",
    "\n",
    "    Description:\n",
    "    - Computes Within-Cluster Sum of Squares (WCSS) for k = 1 to max_k.\n",
    "    - Uses KneeLocator to identify the \"elbow\" point where adding more clusters yields diminishing returns.\n",
    "    - Displays a line plot of WCSS vs. number of clusters with the elbow point marked.\n",
    "    \"\"\"\n",
    "    wcss = []\n",
    "    K = range(1, max_k + 1)\n",
    "    for k in K:\n",
    "        kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "        kmeans.fit(data[[feature]])\n",
    "        wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    kl = KneeLocator(K, wcss, curve=\"convex\", direction=\"decreasing\")\n",
    "    \n",
    "    # Plot elbow curve\n",
    "    plt.figure()\n",
    "    plt.plot(K, wcss, marker='o')\n",
    "    if kl.knee:\n",
    "        plt.axvline(x=kl.knee, color='red', linestyle='--', label=f\"Optimal k = {kl.knee}\")\n",
    "    plt.title(f'Elbow Method for {feature.capitalize()}')\n",
    "    plt.xlabel('Number of Clusters')\n",
    "    plt.ylabel('WCSS')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return kl.knee if kl.knee else 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c37cdf2-d2ef-4fe9-8ada-9d44844620b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- KMeans Scoring for RFM ---\n",
    "def assign_rfm_scores(df: pd.DataFrame, n_clusters: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply KMeans clustering on R, F, M dimensions and assign scores.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): Normalized RFM DataFrame.\n",
    "    n_clusters (int): Number of clusters to use.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with added r_score, f_score, m_score columns.\n",
    "    \"\"\"\n",
    "    for feature in ['recency', 'frequency', 'monetary']:\n",
    "        kmeans = KMeans(n_clusters=n_clusters,n_init = 10, random_state=42)\n",
    "        df[f\"{feature[0]}_score\"] = kmeans.fit_predict(df[[feature]])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432150c-6477-4699-9d7e-8e0e2efc9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = r'C:\\Users\\LENOVO\\Downloads\\RFM.txt'\n",
    "    df = load_and_prepare_data(filepath)\n",
    "\n",
    "    # Normalize\n",
    "    df_clean = df.copy()\n",
    "    df_clean, original_values = normalize_columns(df_clean, ['recency', 'frequency', 'monetary'])\n",
    "\n",
    "    # Find optimal k\n",
    "    optimal_ks = {\n",
    "        feature: find_optimal_k(df_clean, feature)\n",
    "        for feature in ['recency', 'frequency', 'monetary']\n",
    "    }\n",
    "\n",
    "    print(\"Optimal k per feature:\")\n",
    "    for key, val in optimal_ks.items():\n",
    "        print(f\"{key.capitalize()}: {val}\")\n",
    "\n",
    "    # Assign KMeans scores\n",
    "    df_clean = assign_rfm_scores(df_clean, n_clusters=5)\n",
    "\n",
    "    # Map cluster labels (optional: ensure mapping consistency)\n",
    "    score_mapping = {0: 1, 1: 2, 2: 3, 3: 4, 4: 5}\n",
    "    df_clean[['r_score', 'f_score', 'm_score']] = df_clean[['r_score', 'f_score', 'm_score']].replace(score_mapping)\n",
    "\n",
    "    # RFM combined score\n",
    "    df_clean['rfm_score'] = df_clean['r_score'].astype(str) + df_clean['f_score'].astype(str) + df_clean['m_score'].astype(str)\n",
    "\n",
    "    # Denormalize original RFM columns\n",
    "    df_clean = denormalize_columns(df_clean, ['recency', 'frequency', 'monetary'], original_values)\n",
    "\n",
    "    # Merge with RFM segment descriptions\n",
    "    GSHEET_URL = 'https://docs.google.com/spreadsheets/d/1Aqehai_TsPLH_Lo8vFz80rcZ54OQSq3MTpMKimll6TU/edit#gid=884117664'\n",
    "    GSHEET_URL_CSV = GSHEET_URL.replace('/edit#gid=', '/export?format=csv&gid=')\n",
    "    rfm_segments = pd.read_csv(GSHEET_URL_CSV)\n",
    "    rfm_segments['rfm_score'] = rfm_segments['rfm_score'].astype(str)\n",
    "\n",
    "    df_clean = df_clean.merge(rfm_segments, how='left', on='rfm_score')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b75db-64c7-449b-93de-03d7ad36505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd25a3-7eb8-4254-9220-e6ac1a16310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r\"C:\\kukuikk\\Data Analyst\\RFM\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "kc_target = '0001'\n",
    "\n",
    "df_kc = df_clean[df_clean['kc'] == kc_target]\n",
    "\n",
    "if not df_kc.empty:\n",
    "    df_kc.to_excel(os.path.join(output_path, f\"{kc_target}.xlsx\"), index=False)\n",
    "    print(f\"Export selesai untuk KC = {kc_target}!\")\n",
    "else:\n",
    "    print(f\"Tidak ada data untuk KC = {kc_target}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
